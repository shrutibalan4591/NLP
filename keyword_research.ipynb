{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keyword_research.ipynb",
      "provenance": [],
      "mount_file_id": "1Xbx19eXt0jxtOzdNtOBE99rZnCpQDm4O",
      "authorship_tag": "ABX9TyOkiWMoxqBENA/5W33C3jPV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrutibalan4591/NLP/blob/main/keyword_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P37Z8osUJso"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnAZ1oKXPpmP"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/sample_data/kaggle\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHAh3DzMPN3f",
        "outputId": "9a496b75-8200-4297-90bd-75ea1d708ab2"
      },
      "source": [
        "%cd /content/sample_data/kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sample_data/kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN8J24k4cLLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0925a7a-6c4c-46fc-92cf-63e8fb3d0bf2"
      },
      "source": [
        "!kaggle datasets download -d benhamner/nips-papers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/sample_data/kaggle/kaggle.json'\n",
            "Downloading nips-papers.zip to /content/sample_data/kaggle\n",
            " 98% 139M/141M [00:01<00:00, 100MB/s]\n",
            "100% 141M/141M [00:01<00:00, 122MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U02lRcnpOXQR",
        "outputId": "ae087a9b-1dce-40ef-e353-29cdb2a4633a"
      },
      "source": [
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  nips-papers.zip\n",
            "  inflating: authors.csv             \n",
            "replace database.sqlite? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "  inflating: paper_authors.csv       \n",
            "  inflating: papers.csv              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "pGY2o4adTsEw",
        "outputId": "45549682-e758-4ac6-83f4-4bd350a9b557"
      },
      "source": [
        "df = pd.read_csv('/content/sample_data/kaggle/papers.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ...                                         paper_text\n",
              "0     1  ...  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...\n",
              "1    10  ...  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...\n",
              "2   100  ...  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...\n",
              "3  1000  ...  Bayesian Query Construction for Neural\\nNetwor...\n",
              "4  1001  ...  Neural Network Ensembles, Cross\\nValidation, a...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqxMY02CUjeN",
        "outputId": "d62f527d-63de-4f2a-9558-144446caa747"
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc0hZxQVWkyW"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "##Creating a list of custom stopwords\n",
        "new_words = [\"fig\",\"figure\",\"image\",\"sample\",\"using\", \n",
        "             \"show\", \"result\", \"large\", \n",
        "             \"also\", \"one\", \"two\", \"three\", \n",
        "             \"four\", \"five\", \"seven\",\"eight\",\"nine\"]\n",
        "stop_words = list(stop_words.union(new_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2FNomNLXOVW",
        "outputId": "0554f50b-2e07-4e5f-af0d-6b12d7986b47"
      },
      "source": [
        "def pre_process(text):\n",
        "    \n",
        "    # lowercase\n",
        "    text=text.lower()\n",
        "    \n",
        "    #remove tags\n",
        "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
        "    \n",
        "    # remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    \n",
        "    ##Convert to list from string\n",
        "    text = text.split()\n",
        "    \n",
        "    # remove stopwords\n",
        "    text = [word for word in text if word not in stop_words]\n",
        "\n",
        "    # remove words less than three letters\n",
        "    text = [word for word in text if len(word) >= 3]\n",
        "\n",
        "    # lemmatize\n",
        "    lmtzr = WordNetLemmatizer()\n",
        "    text = [lmtzr.lemmatize(word) for word in text]\n",
        "    \n",
        "    return ' '.join(text)\n",
        "\n",
        "docs = df['paper_text'].apply(lambda x:pre_process(x))\n",
        "docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       self organization associative database applica...\n",
              "1       mean field theory layer visual cortex applicat...\n",
              "2       storing covariance associative long term poten...\n",
              "3       bayesian query construction neural network mod...\n",
              "4       neural network ensemble cross validation activ...\n",
              "                              ...                        \n",
              "7236    single transistor learning synapsis paul hasle...\n",
              "7237    bias variance combination least square estimat...\n",
              "7238    real time clustering cmos neural engine serran...\n",
              "7239    learning direction global motion class psychop...\n",
              "7240    correlation interpolation network real time ex...\n",
              "Name: paper_text, Length: 7241, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meHhEU8IYyR0"
      },
      "source": [
        "\n",
        "Using the tf-idf weighting scheme, the keywords are the words with the highest TF-IDF score. For this task, Iâ€™ll first use the CountVectorizer method in Scikit-learn to create a vocabulary and generate the word count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap50uv-WY6xU"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktP0IIRZXiDt"
      },
      "source": [
        "#create a vocabulary of words, \n",
        "cv=CountVectorizer(max_df=0.90,         # ignore words that appear in 95% of documents\n",
        "                   max_features=10000,  # the size of the vocabulary\n",
        "                   ngram_range=(1,3)    # vocabulary contains single words, bigrams, trigrams\n",
        "                  )\n",
        "word_count_vector=cv.fit_transform(docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQquF-slZLYw"
      },
      "source": [
        "Use the TfidfTransformer in Scikit-learn to calculate the reverse frequency of documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow0jTOP9ZHL0",
        "outputId": "68dcefe1-47dd-493b-b265-7dd6a69e9f6b"
      },
      "source": [
        "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
        "tfidf_transformer.fit(word_count_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN9omLQwaKBU"
      },
      "source": [
        "Create a function for the task of Keyword Extraction with Python by using the Tf-IDF vectorization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3r6vZ1eZ-Of",
        "outputId": "fd1b2c44-eaba-445e-b01b-0725a1924dc4"
      },
      "source": [
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "    \n",
        "    #use only topn items from vector\n",
        "    sorted_items = sorted_items[:topn]\n",
        "\n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "\n",
        "    for idx, score in sorted_items:\n",
        "        fname = feature_names[idx]\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        "\n",
        "    #create a tuples of feature,score\n",
        "    #results = zip(feature_vals,score_vals)\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results\n",
        "\n",
        "# get feature names\n",
        "feature_names=cv.get_feature_names()\n",
        "\n",
        "def get_keywords(idx, docs):\n",
        "\n",
        "    #generate tf-idf for the given document\n",
        "    tf_idf_vector=tfidf_transformer.transform(cv.transform([docs[idx]]))\n",
        "\n",
        "    #sort the tf-idf vectors by descending order of scores\n",
        "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "    #extract only the top n; n here is 10\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
        "    \n",
        "    return keywords\n",
        "\n",
        "def print_results(idx,keywords, df):\n",
        "    # now print the results\n",
        "    print(\"\\n=====Title=====\")\n",
        "    print(df['title'][idx])\n",
        "    print(\"\\n=====Abstract=====\")\n",
        "    print(df['abstract'][idx])\n",
        "    print(\"\\n===Keywords===\")\n",
        "    for k in keywords:\n",
        "        print(k,keywords[k])\n",
        "idx=0 # index of row\n",
        "keywords=get_keywords(idx, docs)\n",
        "print_results(idx,keywords, df)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=====Title=====\n",
            "Self-Organization of Associative Database and Its Applications\n",
            "\n",
            "=====Abstract=====\n",
            "Abstract Missing\n",
            "\n",
            "===Keywords===\n",
            "robot 0.352\n",
            "associative 0.219\n",
            "database 0.216\n",
            "camera 0.189\n",
            "letter 0.165\n",
            "learning machine 0.15\n",
            "self organization 0.147\n",
            "position 0.146\n",
            "obstacle 0.136\n",
            "window 0.129\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}